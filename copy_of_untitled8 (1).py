# -*- coding: utf-8 -*-
"""Copy of Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Qbe1nMhcd47y6-PE05kUeBm1dieEYqn
"""

!pip install -q kagglehub ultralytics timm matplotlib

import kagglehub
import os

# Download dataset
dataset_path = kagglehub.dataset_download("atreyamajumdar/mstar-dataset-8-classes")

# Define proper sub-path
if "versions" in dataset_path:
    DATASET_PATH = os.path.join(dataset_path, "Padded_imgs")
else:
    DATASET_PATH = os.path.join(dataset_path, "versions", "1", "Padded_imgs")

# Check path
if not os.path.exists(DATASET_PATH):
    raise FileNotFoundError(f"‚ùå Dataset path does not exist: {DATASET_PATH}")
print(f"‚úÖ Dataset path: {DATASET_PATH}")

import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import random

# Transforms
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# Load dataset
dataset = datasets.ImageFolder(DATASET_PATH, transform=transform)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

# Class names
class_names = dataset.classes
print("Classes:", class_names)

# Show some images
def show_images(images, labels):
    fig, axes = plt.subplots(2, 8, figsize=(18, 5))
    for i, ax in enumerate(axes.flatten()):
        img = images[i].permute(1, 2, 0).squeeze()
        ax.imshow(img, cmap='gray')
        ax.set_title(class_names[labels[i]])
        ax.axis('off')
    plt.tight_layout()
    plt.show()

images, labels = next(iter(dataloader))
show_images(images, labels)

import torch
import torch.nn as nn
import timm

class SARClassifier(nn.Module):
    def __init__(self, num_classes=8):
        super(SARClassifier, self).__init__()
        # Pretrained ResNet50
        self.backbone = timm.create_model("resnet50", pretrained=True)
        self.backbone.fc = nn.Identity()

        # Transformer encoder
        self.attention = nn.TransformerEncoder(
            encoder_layer=nn.TransformerEncoderLayer(d_model=2048, nhead=8),
            num_layers=1
        )

        # Classification head
        self.classifier = nn.Sequential(
            nn.Linear(2048, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        feats = self.backbone(x)  # [B, 2048]
        feats = feats.unsqueeze(1)  # Add sequence dim: [B, 1, 2048]
        feats = self.attention(feats)  # [B, 1, 2048]
        feats = feats.squeeze(1)  # [B, 2048]
        return self.classifier(feats)

# Check model
model = SARClassifier(num_classes=len(class_names)).to("cuda" if torch.cuda.is_available() else "cpu")
print(model)

import torch.optim as optim
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

EPOCHS = 3  # Start small; increase for better results

model.train()
for epoch in range(EPOCHS):
    running_loss = 0.0
    correct = 0
    total = 0

    loop = tqdm(dataloader, desc=f"Epoch [{epoch+1}/{EPOCHS}]")
    for images, labels in loop:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        correct += predicted.eq(labels).sum().item()
        total += labels.size(0)

        loop.set_postfix(loss=loss.item(), acc=100. * correct / total)

print("‚úÖ Training complete.")

model.eval()
correct = 0
total = 0

with torch.no_grad():
    for images, labels in dataloader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = outputs.max(1)
        correct += predicted.eq(labels).sum().item()
        total += labels.size(0)

print(f"üîç Final Accuracy: {100. * correct / total:.2f}%")

!pip install -q ultralytics
from ultralytics import YOLO

# Load YOLOv8 small model
model_yolo = YOLO('yolov8n.pt')  # replace with 'yolov8s.pt' or your trained model if available

# To fine-tune later: model.train(data='your_data.yaml', epochs=50)

from torchvision import datasets
import torchvision.transforms as T
import torch
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os
import random
import kagglehub # Import kagglehub
import matplotlib.pyplot as plt # Import matplotlib for plotting

class SARYOLOCropDataset(Dataset):
    def __init__(self, root, transform=None):
        self.dataset = datasets.ImageFolder(root, transform=T.Resize((256, 256)))
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image, label = self.dataset[idx]

        # YOLO Detection Simulation: return full image as "detected" region
        detected_img = image.crop((16, 16, 240, 240))  # Simulated crop

        if self.transform:
            detected_img = self.transform(detected_img)

        return detected_img, label

# Transforms
transform = T.Compose([
    T.Grayscale(num_output_channels=3),
    T.Resize((224, 224)),
    T.ToTensor()
])

# Define DATASET_PATH again
dataset_path = kagglehub.dataset_download("atreyamajumdar/mstar-dataset-8-classes")
# Define proper sub-path
if "versions" in dataset_path:
    DATASET_PATH = os.path.join(dataset_path, "Padded_imgs")
else:
    DATASET_PATH = os.path.join(dataset_path, "versions", "1", "Padded_imgs")
# Check path
if not os.path.exists(DATASET_PATH):
    raise FileNotFoundError(f"‚ùå Dataset path does not exist: {DATASET_PATH}")
print(f"‚úÖ Dataset path: {DATASET_PATH}")

# Load Dataset with YOLO-style crops
yolo_dataset = SARYOLOCropDataset(DATASET_PATH, transform=transform)
yolo_loader = DataLoader(yolo_dataset, batch_size=16, shuffle=True)

# Class names (assuming you have this defined somewhere)
class_names = yolo_dataset.dataset.classes

# Show some images function
def show_images(images, labels):
    fig, axes = plt.subplots(2, 8, figsize=(18, 5))
    for i, ax in enumerate(axes.flatten()):
        img = images[i].permute(1, 2, 0).squeeze()
        ax.imshow(img, cmap='gray')
        ax.set_title(class_names[labels[i]])
        ax.axis('off')
    plt.tight_layout()
    plt.show()

# Visualize cropped
images, labels = next(iter(yolo_loader))
show_images(images, labels)

# Use same SARClassifier code as before
import torch
from tqdm import tqdm # Import tqdm for progress bar
import torch.nn as nn
import timm # Import timm
from torchvision import datasets # Import datasets for ImageFolder


# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define SARClassifier (copied from previous cell)
class SARClassifier(nn.Module):
    def __init__(self, num_classes=8):
        super(SARClassifier, self).__init__()
        # Pretrained ResNet50
        self.backbone = timm.create_model("resnet50", pretrained=True)
        self.backbone.fc = nn.Identity()

        # Transformer encoder
        self.attention = nn.TransformerEncoder(
            encoder_layer=nn.TransformerEncoderLayer(d_model=2048, nhead=8),
            num_layers=1
        )

        # Classification head
        self.classifier = nn.Sequential(
            nn.Linear(2048, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        feats = self.backbone(x)  # [B, 2048]
        feats = feats.unsqueeze(1)  # Add sequence dim: [B, 1, 2048]
        feats = self.attention(feats)  # [B, 1, 2048]
        feats = feats.squeeze(1)  # [B, 2048]
        return self.classifier(feats)

# Assuming DATASET_PATH is already defined from a previous cell:
# Load Dataset for getting class names using ImageFolder
dataset = datasets.ImageFolder(DATASET_PATH)
class_names = dataset.classes  # Get class names from the dataset


model = SARClassifier(num_classes=len(class_names)).to(device)

# Optimizer & loss
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# Training loop
EPOCHS = 3
model.train()
for epoch in range(EPOCHS):
    running_loss = 0
    correct = 0
    total = 0
    loop = tqdm(yolo_loader, desc=f"Epoch [{epoch+1}/{EPOCHS}]")

    for images, labels in loop:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        _, preds = outputs.max(1)
        correct += preds.eq(labels).sum().item()
        total += labels.size(0)
        loop.set_postfix(loss=loss.item(), acc=100. * correct / total)

print("‚úÖ resent dataset classifier training done.")